{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625137a7",
   "metadata": {},
   "source": [
    "\n",
    "## REPRODUCING TABLE 1: Predicting GDP per capita\n",
    "### Paper: \"Multidimensional tie strength and economic development\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef65bb6",
   "metadata": {},
   "source": [
    "### Final approach and results ###\n",
    "The code below shows the result that better match the Table 1 from the paper. We used the pre-computed Diversity Measures of the regression_file.csv dataset. The dataset contained multiple versions of each diversity metric with different configurations:\n",
    "\n",
    "- diversity_spatial_all_minstrength_X (where X = 1, 2, 3, 4, 5)\n",
    "- spatial_diversity_[dimension]_[threshold] (e.g., spatial_diversity_knowledge_0.99)\n",
    "\n",
    "Therefore, we systematically tested different column combinations, to finally check that by using the pre-computed diversity columns with minstrength_5, we achieved the closest match to the paper's published results.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ff9fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 44 states\n",
      "Excluded states: DC, AK, MS, WV, SD, WY, ND\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/regression_file.csv')\n",
    "dim_df = pd.read_csv('data/reddit_messages_dimensions.csv', sep=\"|\")\n",
    "\n",
    "# Calculate population density\n",
    "state_areas = {\n",
    "    \"AL\": 131170, \"AK\": 1723337, \"AZ\": 295234, \"AR\": 137732,\n",
    "    \"CA\": 423967, \"CO\": 269601, \"CT\": 14357, \"DE\": 6446,\n",
    "    \"FL\": 170312, \"GA\": 153910, \"HI\": 28313, \"ID\": 216443,\n",
    "    \"IL\": 149995, \"IN\": 94326, \"IA\": 145746, \"KS\": 213100,\n",
    "    \"KY\": 104656, \"LA\": 135659, \"ME\": 91633, \"MD\": 32131,\n",
    "    \"MA\": 27336, \"MI\": 250487, \"MN\": 225163, \"MS\": 125438,\n",
    "    \"MO\": 180540, \"MT\": 380831, \"NE\": 200330, \"NV\": 286380,\n",
    "    \"NH\": 24214, \"NJ\": 22591, \"NM\": 314917, \"NY\": 141297,\n",
    "    \"NC\": 139391, \"ND\": 183108, \"OH\": 116098, \"OK\": 181037,\n",
    "    \"OR\": 254806, \"PA\": 119280, \"RI\": 4001, \"SC\": 82933,\n",
    "    \"SD\": 199729, \"TN\": 109153, \"TX\": 695662, \"UT\": 219882,\n",
    "    \"VT\": 24906, \"VA\": 110787, \"WA\": 184661, \"WV\": 62756,\n",
    "    \"WI\": 169635, \"WY\": 253335, \"DC\": 177\n",
    "}\n",
    "\n",
    "df[\"population_density\"] = df[\"population_2019\"] / df[\"state_code\"].map(state_areas)\n",
    "\n",
    "# Filter to 44 states (exclude DC, AK, MS, WV, SD, WY, ND)\n",
    "excluded = [\"DC\", \"AK\", \"MS\", \"WV\", \"SD\", \"WY\", \"ND\"]\n",
    "df = df[~df[\"state_code\"].isin(excluded)].copy()\n",
    "\n",
    "print(f\"Sample size: {len(df)} states\")\n",
    "print(f\"Excluded states: {', '.join(excluded)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6bc725f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TABLE 1 REPRODUCTION RESULTS\n",
      "================================================================================\n",
      "Model        Variable                       β       SE        p   R²_adj     DW\n",
      "──────────── ─────────────────────── ──────── ──────── ──────── ──────── ──────\n",
      "Model 1      Population density         0.548    0.129    0.000    0.283   1.96\n",
      "                                                                               \n",
      "Model 2      Population density         0.492    0.139    0.001    0.286   2.02\n",
      "             D_spatial                  0.148    0.139    0.293                \n",
      "                                                                               \n",
      "Model 3      Population density         0.400    0.097    0.000    0.623   2.05\n",
      "             D_knowledge                0.842    0.136    0.000                \n",
      "             D_support                 -0.467    0.133    0.001                \n",
      "\n",
      "================================================================================\n",
      "COMPARISON WITH PAPER (TABLE 1)\n",
      "================================================================================\n",
      "Variable                   Paper β    Our β     Diff Match\n",
      "───────────────────────── ──────── ──────── ──────── ─────\n",
      "Pop density (Model 1)        0.636    0.548    0.088     ✓\n",
      "Pop density (Model 2)        0.565    0.492    0.073     ✓\n",
      "D_spatial (Model 2)          0.243    0.148    0.095     ✓\n",
      "Pop density (Model 3)        0.471    0.400    0.071     ✓\n",
      "D_knowledge (Model 3)        1.033    0.842    0.191     ✗\n",
      "D_support (Model 3)         -0.555   -0.467    0.088     ✓\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION USED:\n",
      "  - Full graph diversity: diversity_spatial_all_minstrength_5\n",
      "  - Knowledge diversity: spatial_diversity_knowledge_0.99\n",
      "  - Support diversity: spatial_diversity_support_0.99\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DETAILED REGRESSION OUTPUTS\n",
      "================================================================================\n",
      "\n",
      "--- MODEL 1: Population Density Only ---\n",
      "                              OLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     gdp per capita (2017)   R-squared:                       0.300\n",
      "Model:                               OLS   Adj. R-squared:                  0.283\n",
      "Method:                    Least Squares   F-statistic:                     18.01\n",
      "Date:                   Mon, 10 Nov 2025   Prob (F-statistic):           0.000119\n",
      "Time:                           16:04:38   Log-Likelihood:                -54.078\n",
      "No. Observations:                     44   AIC:                             112.2\n",
      "Df Residuals:                         42   BIC:                             115.7\n",
      "Df Model:                              1                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const              -3.331e-16      0.128  -2.61e-15      1.000      -0.258       0.258\n",
      "population_density     0.5478      0.129      4.243      0.000       0.287       0.808\n",
      "==============================================================================\n",
      "Omnibus:                        4.142   Durbin-Watson:                   1.963\n",
      "Prob(Omnibus):                  0.126   Jarque-Bera (JB):                1.823\n",
      "Skew:                           0.089   Prob(JB):                        0.402\n",
      "Kurtosis:                       2.019   Cond. No.                         1.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "--- MODEL 2: Full Communication Graph ---\n",
      "                              OLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     gdp per capita (2017)   R-squared:                       0.319\n",
      "Model:                               OLS   Adj. R-squared:                  0.286\n",
      "Method:                    Least Squares   F-statistic:                     9.598\n",
      "Date:                   Mon, 10 Nov 2025   Prob (F-statistic):           0.000381\n",
      "Time:                           16:04:38   Log-Likelihood:                -53.478\n",
      "No. Observations:                     44   AIC:                             113.0\n",
      "Df Residuals:                         41   BIC:                             118.3\n",
      "Df Model:                              2                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const       -3.331e-16      0.127  -2.61e-15      1.000      -0.257       0.257\n",
      "pop_density     0.4917      0.139      3.531      0.001       0.210       0.773\n",
      "D_spatial       0.1482      0.139      1.064      0.293      -0.133       0.429\n",
      "==============================================================================\n",
      "Omnibus:                        3.033   Durbin-Watson:                   2.024\n",
      "Prob(Omnibus):                  0.219   Jarque-Bera (JB):                1.570\n",
      "Skew:                           0.097   Prob(JB):                        0.456\n",
      "Kurtosis:                       2.095   Cond. No.                         1.49\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "--- MODEL 3: Dimension-Specific Graphs ---\n",
      "                              OLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     gdp per capita (2017)   R-squared:                       0.649\n",
      "Model:                               OLS   Adj. R-squared:                  0.623\n",
      "Method:                    Least Squares   F-statistic:                     24.69\n",
      "Date:                   Mon, 10 Nov 2025   Prob (F-statistic):           3.32e-09\n",
      "Time:                           16:04:38   Log-Likelihood:                -38.876\n",
      "No. Observations:                     44   AIC:                             85.75\n",
      "Df Residuals:                         40   BIC:                             92.89\n",
      "Df Model:                              3                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const       -3.331e-16      0.093   -3.6e-15      1.000      -0.187       0.187\n",
      "pop_density     0.4001      0.097      4.138      0.000       0.205       0.595\n",
      "D_knowledge     0.8420      0.136      6.194      0.000       0.567       1.117\n",
      "D_support      -0.4669      0.133     -3.512      0.001      -0.736      -0.198\n",
      "==============================================================================\n",
      "Omnibus:                        2.562   Durbin-Watson:                   2.048\n",
      "Prob(Omnibus):                  0.278   Jarque-Bera (JB):                2.358\n",
      "Skew:                           0.547   Prob(JB):                        0.308\n",
      "Kurtosis:                       2.701   Cond. No.                         2.52\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Select variables (best configuration: minstrength_5)\n",
    "data = df[[\n",
    "    'gdp per capita (2017)',\n",
    "    'population_density',\n",
    "    'diversity_spatial_all_minstrength_5',\n",
    "    'spatial_diversity_knowledge_0.99',\n",
    "    'spatial_diversity_support_0.99'\n",
    "]].dropna()\n",
    "\n",
    "# Standardize variables\n",
    "def standardize(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "y = standardize(data['gdp per capita (2017)'])\n",
    "x1 = standardize(data['population_density'])\n",
    "x2 = standardize(data['diversity_spatial_all_minstrength_5'])\n",
    "x3 = standardize(data['spatial_diversity_knowledge_0.99'])\n",
    "x4 = standardize(data['spatial_diversity_support_0.99'])\n",
    "\n",
    "# MODEL 1: Population density only\n",
    "X1 = sm.add_constant(x1)\n",
    "model1 = sm.OLS(y, X1).fit()\n",
    "\n",
    "# MODEL 2: Full communication graph\n",
    "X2 = sm.add_constant(pd.DataFrame({'pop_density': x1, 'D_spatial': x2}))\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "\n",
    "# MODEL 3: Dimension-specific graphs\n",
    "X3 = sm.add_constant(pd.DataFrame({\n",
    "    'pop_density': x1, \n",
    "    'D_knowledge': x3, \n",
    "    'D_support': x4\n",
    "}))\n",
    "model3 = sm.OLS(y, X3).fit()\n",
    "\n",
    "#Results summary:\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TABLE 1 REPRODUCTION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = [\n",
    "    ['Model', 'Variable', 'β', 'SE', 'p', 'R²_adj', 'DW'],\n",
    "    ['─'*12, '─'*23, '─'*8, '─'*8, '─'*8, '─'*8, '─'*6],\n",
    "    ['Model 1', 'Population density', \n",
    "     f\"{model1.params.iloc[1]:.3f}\", \n",
    "     f\"{model1.bse.iloc[1]:.3f}\", \n",
    "     f\"{model1.pvalues.iloc[1]:.3f}\",\n",
    "     f\"{model1.rsquared_adj:.3f}\",\n",
    "     f\"{durbin_watson(model1.resid):.2f}\"],\n",
    "    ['', '', '', '', '', '', ''],\n",
    "    ['Model 2', 'Population density',\n",
    "     f\"{model2.params.iloc[1]:.3f}\",\n",
    "     f\"{model2.bse.iloc[1]:.3f}\",\n",
    "     f\"{model2.pvalues.iloc[1]:.3f}\",\n",
    "     f\"{model2.rsquared_adj:.3f}\",\n",
    "     f\"{durbin_watson(model2.resid):.2f}\"],\n",
    "    ['', 'D_spatial',\n",
    "     f\"{model2.params.iloc[2]:.3f}\",\n",
    "     f\"{model2.bse.iloc[2]:.3f}\",\n",
    "     f\"{model2.pvalues.iloc[2]:.3f}\",\n",
    "     '', ''],\n",
    "    ['', '', '', '', '', '', ''],\n",
    "    ['Model 3', 'Population density',\n",
    "     f\"{model3.params.iloc[1]:.3f}\",\n",
    "     f\"{model3.bse.iloc[1]:.3f}\",\n",
    "     f\"{model3.pvalues.iloc[1]:.3f}\",\n",
    "     f\"{model3.rsquared_adj:.3f}\",\n",
    "     f\"{durbin_watson(model3.resid):.2f}\"],\n",
    "    ['', 'D_knowledge',\n",
    "     f\"{model3.params.iloc[2]:.3f}\",\n",
    "     f\"{model3.bse.iloc[2]:.3f}\",\n",
    "     f\"{model3.pvalues.iloc[2]:.3f}\",\n",
    "     '', ''],\n",
    "    ['', 'D_support',\n",
    "     f\"{model3.params.iloc[3]:.3f}\",\n",
    "     f\"{model3.bse.iloc[3]:.3f}\",\n",
    "     f\"{model3.pvalues.iloc[3]:.3f}\",\n",
    "     '', ''],\n",
    "]\n",
    "\n",
    "for row in results:\n",
    "    print(f\"{row[0]:<12} {row[1]:<23} {row[2]:>8} {row[3]:>8} {row[4]:>8} {row[5]:>8} {row[6]:>6}\")\n",
    "\n",
    "\n",
    "#Table to compare with paper results:\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON WITH PAPER (TABLE 1)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparisons = [\n",
    "    ['Variable', 'Paper β', 'Our β', 'Diff', 'Match'],\n",
    "    ['─'*25, '─'*8, '─'*8, '─'*8, '─'*5],\n",
    "    ['Pop density (Model 1)', '0.636', f\"{model1.params.iloc[1]:.3f}\", \n",
    "     f\"{abs(0.636 - model1.params.iloc[1]):.3f}\", \n",
    "     '✓' if abs(0.636 - model1.params.iloc[1]) < 0.10 else '✗'],\n",
    "    ['Pop density (Model 2)', '0.565', f\"{model2.params.iloc[1]:.3f}\",\n",
    "     f\"{abs(0.565 - model2.params.iloc[1]):.3f}\",\n",
    "     '✓' if abs(0.565 - model2.params.iloc[1]) < 0.10 else '✗'],\n",
    "    ['D_spatial (Model 2)', '0.243', f\"{model2.params.iloc[2]:.3f}\",\n",
    "     f\"{abs(0.243 - model2.params.iloc[2]):.3f}\",\n",
    "     '✓' if abs(0.243 - model2.params.iloc[2]) < 0.10 else '✗'],\n",
    "    ['Pop density (Model 3)', '0.471', f\"{model3.params.iloc[1]:.3f}\",\n",
    "     f\"{abs(0.471 - model3.params.iloc[1]):.3f}\",\n",
    "     '✓' if abs(0.471 - model3.params.iloc[1]) < 0.10 else '✗'],\n",
    "    ['D_knowledge (Model 3)', '1.033', f\"{model3.params.iloc[2]:.3f}\",\n",
    "     f\"{abs(1.033 - model3.params.iloc[2]):.3f}\",\n",
    "     '✓' if abs(1.033 - model3.params.iloc[2]) < 0.10 else '✗'],\n",
    "    ['D_support (Model 3)', '-0.555', f\"{model3.params.iloc[3]:.3f}\",\n",
    "     f\"{abs(-0.555 - model3.params.iloc[3]):.3f}\",\n",
    "     '✓' if abs(-0.555 - model3.params.iloc[3]) < 0.10 else '✗'],\n",
    "]\n",
    "\n",
    "for row in comparisons:\n",
    "    print(f\"{row[0]:<25} {row[1]:>8} {row[2]:>8} {row[3]:>8} {row[4]:>5}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFIGURATION USED:\")\n",
    "print(\"  - Full graph diversity: diversity_spatial_all_minstrength_5\")\n",
    "print(\"  - Knowledge diversity: spatial_diversity_knowledge_0.99\")\n",
    "print(\"  - Support diversity: spatial_diversity_support_0.99\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "#full regression summaries\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED REGRESSION OUTPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n--- MODEL 1: Population Density Only ---\")\n",
    "print(model1.summary())\n",
    "\n",
    "print(\"\\n--- MODEL 2: Full Communication Graph ---\")\n",
    "print(model2.summary())\n",
    "\n",
    "print(\"\\n--- MODEL 3: Dimension-Specific Graphs ---\")\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f1fa8",
   "metadata": {},
   "source": [
    "## First approach ##\n",
    "However, our first approach was to manually compute spatial diversity measures following equations (6-11) from the paper. We implemented the following workflow:\n",
    "- Step 1: Load edge-level data from Reddit messages\n",
    "- Step 2: For each user, calculate spatial diversity (normalized entropy of destination states)\n",
    "- Step 3: Aggregate user-level diversities to state level by computing means\n",
    "- Step 4: Run three regression models predicting GDP per capita\n",
    "\n",
    "This approach involved:\n",
    "- Computing user-level spatial diversity for all edges (full communication graph)\n",
    "- Computing dimension-specific diversities by filtering edges where knowledge_binary_adaptive_0.99 == 1 or support_binary_adaptive_0.99 == 1\n",
    "- Aggregating to state level using mean diversity across users in each state.\n",
    "\n",
    "But as showed in the final Table after the following code, the results were differents from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e379ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to compute user-level diversity given a user->state weight table\n",
    "def compute_user_diversities(user_state_weights_df):\n",
    "    \"\"\"\n",
    "    user_state_weights_df: DataFrame with columns ['author', 'author_state_code', 'dest_state_code', 'weight']\n",
    "    returns: DataFrame [author, author_state_code, D_spatial_user]\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # group by author\n",
    "    for author, grp in user_state_weights_df.groupby(\"author\"):\n",
    "        src_state = grp[\"author_state_code\"].iloc[0]\n",
    "        weights = grp[\"weight\"].values.astype(float)\n",
    "        total = weights.sum()\n",
    "        if total <= 0 or len(weights) <= 1:\n",
    "            D = 0.0\n",
    "        else:\n",
    "            p = weights / total\n",
    "            H = -np.sum(p * np.log(p))\n",
    "            # normalize by log(n_dest)\n",
    "            n_dest = len(weights)\n",
    "            H_norm = H / np.log(n_dest) if n_dest > 1 else 0.0\n",
    "            # paper uses \"1 - normalized_entropy\"\n",
    "            D = 1.0 - H_norm\n",
    "        rows.append((author, src_state, D))\n",
    "    return pd.DataFrame(rows, columns=[\"author\", \"author_state_code\", \"D_spatial_user\"])\n",
    "\n",
    "# --- 1) Full graph: build user->dest_state counts (all messages)\n",
    "user_state_all = (\n",
    "    dim_df.groupby([\"author\", \"author_state_code\", \"dest_state_code\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"weight\")\n",
    ")\n",
    "\n",
    "# compute per-user diversity (full graph)\n",
    "user_div_all = compute_user_diversities(user_state_all)\n",
    "\n",
    "# 2) Knowledge graph: build user->dest_state counts only for knowledge messages\n",
    "col_k = \"knowledge_binary_adaptive_0.99\"  # adapt if your column name differs\n",
    "user_state_know = (\n",
    "    dim_df[dim_df[col_k] == 1]\n",
    "    .groupby([\"author\", \"author_state_code\", \"dest_state_code\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"weight\")\n",
    ")\n",
    "user_div_know = compute_user_diversities(user_state_know)\n",
    "\n",
    "# 3) Support graph\n",
    "col_s = \"support_binary_adaptive_0.99\"\n",
    "user_state_support = (\n",
    "    dim_df[dim_df[col_s] == 1]\n",
    "    .groupby([\"author\", \"author_state_code\", \"dest_state_code\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"weight\")\n",
    ")\n",
    "user_div_support = compute_user_diversities(user_state_support)\n",
    "\n",
    "# 4) Aggregate to state level by averaging user-level D\n",
    "\n",
    "D_all_state = user_div_all.groupby(\"author_state_code\")[\"D_spatial_user\"].mean().reset_index().rename(\n",
    "    columns={\"author_state_code\":\"state_code\", \"D_spatial_user\":\"D_spatial_all\"}\n",
    ")\n",
    "\n",
    "D_know_state = user_div_know.groupby(\"author_state_code\")[\"D_spatial_user\"].mean().reset_index().rename(\n",
    "    columns={\"author_state_code\":\"state_code\", \"D_spatial_user\":\"D_spatial_knowledge\"}\n",
    ")\n",
    "\n",
    "D_support_state = user_div_support.groupby(\"author_state_code\")[\"D_spatial_user\"].mean().reset_index().rename(\n",
    "    columns={\"author_state_code\":\"state_code\", \"D_spatial_user\":\"D_spatial_support\"}\n",
    ")\n",
    "\n",
    "# merge with df\n",
    "reg = df.copy()  # df is your regression file loaded at top of notebook\n",
    "reg = reg.merge(D_all_state, on=\"state_code\", how=\"left\")\n",
    "reg = reg.merge(D_know_state, on=\"state_code\", how=\"left\")\n",
    "reg = reg.merge(D_support_state, on=\"state_code\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa52d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Baseline\n",
      "population_density             β=0.542  SE=0.195  p=0.005\n",
      "Adj R2 = 0.283, Durbin-Watson = 1.963\n",
      "\n",
      "Model: Full graph\n",
      "population_density             β=0.549  SE=0.159  p=0.001\n",
      "D_spatial_all                  β=0.353  SE=0.112  p=0.002\n",
      "Adj R2 = 0.400, Durbin-Watson = 2.025\n",
      "\n",
      "Model: Dim-specific\n",
      "population_density             β=0.495  SE=0.177  p=0.005\n",
      "D_spatial_knowledge            β=0.300  SE=0.202  p=0.138\n",
      "D_spatial_support              β=0.107  SE=0.239  p=0.653\n",
      "Adj R2 = 0.397, Durbin-Watson = 1.971\n"
     ]
    }
   ],
   "source": [
    "# Standardize and run regressions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "def standardized_ols_df(y, X_df):\n",
    "    scaler = StandardScaler()\n",
    "    X_std = pd.DataFrame(scaler.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
    "    y_std = (y - y.mean()) / y.std()\n",
    "    X_std = sm.add_constant(X_std)\n",
    "    model = sm.OLS(y_std, X_std).fit(cov_type=\"HC3\")  # robust SE\n",
    "    return model\n",
    "\n",
    "y = reg[\"gdp per capita (2017)\"]\n",
    "\n",
    "X_a = reg[[\"population_density\"]]\n",
    "X_b = reg[[\"population_density\", \"D_spatial_all\"]]\n",
    "X_c = reg[[\"population_density\", \"D_spatial_knowledge\", \"D_spatial_support\"]]\n",
    "\n",
    "m1 = standardized_ols_df(y, X_a)\n",
    "m2 = standardized_ols_df(y, X_b)\n",
    "m3 = standardized_ols_df(y, X_c)\n",
    "\n",
    "def summarize_model(name, model):\n",
    "    vars = [v for v in model.params.index if v != \"const\"]\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    for v in vars:\n",
    "        print(f\"{v:30s} β={model.params[v]:.3f}  SE={model.bse[v]:.3f}  p={model.pvalues[v]:.3f}\")\n",
    "    print(f\"Adj R2 = {model.rsquared_adj:.3f}, Durbin-Watson = {durbin_watson(model.resid):.3f}\")\n",
    "\n",
    "summarize_model(\"Baseline\", m1)\n",
    "summarize_model(\"Full graph\", m2)\n",
    "summarize_model(\"Dim-specific\", m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "350f915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TABLE 1 REPRODUCTION RESULTS\n",
      "================================================================================\n",
      "Model        Variable                       β       SE        p   R²_adj     DW\n",
      "──────────── ─────────────────────── ──────── ──────── ──────── ──────── ──────\n",
      "Model 1      Population density         0.542    0.195    0.005    0.283   1.96\n",
      "                                                                               \n",
      "Model 2      Population density         0.549    0.159    0.001    0.400   2.02\n",
      "             D_spatial                  0.353    0.112    0.002                \n",
      "                                                                               \n",
      "Model 3      Population density         0.495    0.177    0.005    0.397   1.97\n",
      "             D_knowledge                0.300    0.202    0.138                \n",
      "             D_support                  0.107    0.239    0.653                \n",
      "\n",
      "================================================================================\n",
      "COMPARISON WITH PAPER (TABLE 1)\n",
      "================================================================================\n",
      "Variable                   Paper β    Our β     Diff Match\n",
      "───────────────────────── ──────── ──────── ──────── ─────\n",
      "Pop density (Model 1)        0.636    0.542    0.094     ✓\n",
      "Pop density (Model 2)        0.565    0.549    0.016     ✓\n",
      "D_spatial (Model 2)          0.243    0.353    0.110     ✗\n",
      "Pop density (Model 3)        0.471    0.495    0.024     ✓\n",
      "D_knowledge (Model 3)        1.033    0.300    0.733     ✗\n",
      "D_support (Model 3)         -0.555    0.107    0.662     ✗\n"
     ]
    }
   ],
   "source": [
    "#Results summary:\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TABLE 1 REPRODUCTION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = [\n",
    "    ['Model', 'Variable', 'β', 'SE', 'p', 'R²_adj', 'DW'],\n",
    "    ['─'*12, '─'*23, '─'*8, '─'*8, '─'*8, '─'*8, '─'*6],\n",
    "    ['Model 1', 'Population density', \n",
    "     f\"{m1.params.iloc[1]:.3f}\", \n",
    "     f\"{m1.bse.iloc[1]:.3f}\", \n",
    "     f\"{m1.pvalues.iloc[1]:.3f}\",\n",
    "     f\"{m1.rsquared_adj:.3f}\",\n",
    "     f\"{durbin_watson(m1.resid):.2f}\"],\n",
    "    ['', '', '', '', '', '', ''],\n",
    "    ['Model 2', 'Population density',\n",
    "     f\"{m2.params.iloc[1]:.3f}\",\n",
    "     f\"{m2.bse.iloc[1]:.3f}\",\n",
    "     f\"{m2.pvalues.iloc[1]:.3f}\",\n",
    "     f\"{m2.rsquared_adj:.3f}\",\n",
    "     f\"{durbin_watson(m2.resid):.2f}\"],\n",
    "    ['', 'D_spatial',\n",
    "     f\"{m2.params.iloc[2]:.3f}\",\n",
    "     f\"{m2.bse.iloc[2]:.3f}\",\n",
    "     f\"{m2.pvalues.iloc[2]:.3f}\",\n",
    "     '', ''],\n",
    "    ['', '', '', '', '', '', ''],\n",
    "    ['Model 3', 'Population density',\n",
    "     f\"{m3.params.iloc[1]:.3f}\",\n",
    "     f\"{m3.bse.iloc[1]:.3f}\",\n",
    "     f\"{m3.pvalues.iloc[1]:.3f}\",\n",
    "     f\"{m3.rsquared_adj:.3f}\",\n",
    "     f\"{durbin_watson(m3.resid):.2f}\"],\n",
    "    ['', 'D_knowledge',\n",
    "     f\"{m3.params.iloc[2]:.3f}\",\n",
    "     f\"{m3.bse.iloc[2]:.3f}\",\n",
    "     f\"{m3.pvalues.iloc[2]:.3f}\",\n",
    "     '', ''],\n",
    "    ['', 'D_support',\n",
    "     f\"{m3.params.iloc[3]:.3f}\",\n",
    "     f\"{m3.bse.iloc[3]:.3f}\",\n",
    "     f\"{m3.pvalues.iloc[3]:.3f}\",\n",
    "     '', ''],\n",
    "]\n",
    "\n",
    "for row in results:\n",
    "    print(f\"{row[0]:<12} {row[1]:<23} {row[2]:>8} {row[3]:>8} {row[4]:>8} {row[5]:>8} {row[6]:>6}\")\n",
    "\n",
    "\n",
    "#Table to compare with paper results:\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON WITH PAPER (TABLE 1)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparisons = [\n",
    "    ['Variable', 'Paper β', 'Our β', 'Diff', 'Match'],\n",
    "    ['─'*25, '─'*8, '─'*8, '─'*8, '─'*5],\n",
    "    ['Pop density (Model 1)', '0.636', f\"{m1.params.iloc[1]:.3f}\", \n",
    "     f\"{abs(0.636 - m1.params.iloc[1]):.3f}\", \n",
    "     '✓' if abs(0.636 - m1.params.iloc[1]) < 0.10 else '✗'],\n",
    "    ['Pop density (Model 2)', '0.565', f\"{m2.params.iloc[1]:.3f}\",\n",
    "     f\"{abs(0.565 - m2.params.iloc[1]):.3f}\",\n",
    "     '✓' if abs(0.565 - m2.params.iloc[1]) < 0.10 else '✗'],\n",
    "    ['D_spatial (Model 2)', '0.243', f\"{m2.params.iloc[2]:.3f}\",\n",
    "     f\"{abs(0.243 - m2.params.iloc[2]):.3f}\",\n",
    "     '✓' if abs(0.243 - m2.params.iloc[2]) < 0.10 else '✗'],\n",
    "    ['Pop density (Model 3)', '0.471', f\"{m3.params.iloc[1]:.3f}\",\n",
    "     f\"{abs(0.471 - m3.params.iloc[1]):.3f}\",\n",
    "     '✓' if abs(0.471 - m3.params.iloc[1]) < 0.10 else '✗'],\n",
    "    ['D_knowledge (Model 3)', '1.033', f\"{m3.params.iloc[2]:.3f}\",\n",
    "     f\"{abs(1.033 - m3.params.iloc[2]):.3f}\",\n",
    "     '✓' if abs(1.033 - m3.params.iloc[2]) < 0.10 else '✗'],\n",
    "    ['D_support (Model 3)', '-0.555', f\"{m3.params.iloc[3]:.3f}\",\n",
    "     f\"{abs(-0.555 - m3.params.iloc[3]):.3f}\",\n",
    "     '✓' if abs(-0.555 - m3.params.iloc[3]) < 0.10 else '✗'],\n",
    "]\n",
    "\n",
    "for row in comparisons:\n",
    "    print(f\"{row[0]:<25} {row[1]:>8} {row[2]:>8} {row[3]:>8} {row[4]:>5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "damin2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
